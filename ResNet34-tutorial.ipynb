{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Things ResNet\n",
    "\n",
    "**We have had the below output in several of our lessons. I took this snipet out of another lesson code, so that way if anyone is interested in my tirade of what's going on here can get a deeper understanding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================================\n",
    "Layer (type)         Output Shape         Param #    Trainable \n",
    "======================================================================\n",
    "Conv2d               [8, 64, 180, 240]    9408       False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 180, 240]    128        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 64, 180, 240]    0          False     \n",
    "______________________________________________________________________\n",
    "MaxPool2d            [8, 64, 90, 120]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 64, 90, 120]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 64, 90, 120]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 64, 90, 120]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 64, 90, 120]     36864      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     73728      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 128, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     8192       False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 128, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 128, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 128, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 128, 45, 60]     147456     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     294912     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     32768      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 23, 30]     589824     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     1179648    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 12, 15]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     131072     False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 12, 15]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 12, 15]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 12, 15]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 1024, 12, 15]    4719616    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 1024, 12, 15]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 12, 15]     4719104    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 12, 15]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 1024, 12, 15]    525312     True      \n",
    "______________________________________________________________________\n",
    "PixelShuffle         [8, 256, 24, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "ReplicationPad2d     [8, 256, 25, 31]     0          False     \n",
    "______________________________________________________________________\n",
    "AvgPool2d            [8, 256, 24, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 1024, 12, 15]    0          False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 23, 30]     2359808    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 23, 30]     2359808    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 23, 30]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 1024, 23, 30]    525312     True      \n",
    "______________________________________________________________________\n",
    "PixelShuffle         [8, 256, 46, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "ReplicationPad2d     [8, 256, 47, 61]     0          False     \n",
    "______________________________________________________________________\n",
    "AvgPool2d            [8, 256, 46, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 1024, 23, 30]    0          False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 384, 45, 60]     1327488    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 384, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 384, 45, 60]     1327488    True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 384, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 384, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 768, 45, 60]     295680     True      \n",
    "______________________________________________________________________\n",
    "PixelShuffle         [8, 192, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "ReplicationPad2d     [8, 192, 91, 121]    0          False     \n",
    "______________________________________________________________________\n",
    "AvgPool2d            [8, 192, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 768, 45, 60]     0          False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 90, 120]    590080     True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 256, 90, 120]    590080     True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 256, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 512, 90, 120]    131584     True      \n",
    "______________________________________________________________________\n",
    "PixelShuffle         [8, 128, 180, 240]   0          False     \n",
    "______________________________________________________________________\n",
    "ReplicationPad2d     [8, 128, 181, 241]   0          False     \n",
    "______________________________________________________________________\n",
    "AvgPool2d            [8, 128, 180, 240]   0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 512, 90, 120]    0          False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [8, 64, 180, 240]    128        True      \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 96, 180, 240]    165984     True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 96, 180, 240]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 96, 180, 240]    83040      True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 96, 180, 240]    0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 192, 180, 240]   0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 384, 180, 240]   37248      True      \n",
    "______________________________________________________________________\n",
    "PixelShuffle         [8, 96, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "ReplicationPad2d     [8, 96, 361, 481]    0          False     \n",
    "______________________________________________________________________\n",
    "AvgPool2d            [8, 96, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 384, 180, 240]   0          False     \n",
    "______________________________________________________________________\n",
    "MergeLayer           [8, 99, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 49, 360, 480]    43708      True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 49, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 99, 360, 480]    43758      True      \n",
    "______________________________________________________________________\n",
    "ReLU                 [8, 99, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "MergeLayer           [8, 99, 360, 480]    0          False     \n",
    "______________________________________________________________________\n",
    "Conv2d               [8, 12, 360, 480]    1200       True      \n",
    "______________________________________________________________________\n",
    "\n",
    "Total params:  41133018\n",
    "Total trainable params:  19865370\n",
    "Total non-trainable params:  21267648"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I wanted to take a moment to clarify some of my mentionings in the first few lessons. More specifically, what are layers? This portion will be especially helpful, because we can also get a glimpse at a U-net that is used for these types of models in later lessons.**\n",
    "\n",
    "**Also, I have mentioned before that when we train our models using the 'fit_one_cycle' class, it first runs with the layers from the base architect model 'frozen.' Then when we're satisfied with our learning rate tweaks we then 'unfreeze' the base model. This is where it all comes together.**\n",
    "\n",
    "**Let's start with the basics at the left column of 'Layer'(the output from the cell above). These are those things between our inputted data and our outputted results. This is where all of the magic happens. If you scroll down the column, we can see a sort of repetition going on here. What are these things? Let's talk about that;**\n",
    "\n",
    "**In the beginning, there was data. We said, let this be linear, and it was so. In this particular case our data provided was images. Let's answer a few questions first;**\n",
    "\n",
    "**What is an image?:** \n",
    "- **An Image is an arrangement of pixels in 2 dimensional layers. Each pixel has a value range from 0 to 255 to depict the amount of activation (intensity) from that pixel. And most images have a total of 3 2-dimensional layers to represent the 3 primary color layers of Red, Green and Blue. When we put these elements together, we have a picture in color. Provided below is an image showing us the various pixel versions of colors. In this case, it's showing us all three layers combined in the array. This array is arranged by [red color, green color, blue color] which is equivalent to [90,0,53] in the image.**\n",
    "\n",
    "<img src=\"https://ai.stanford.edu/~syyeung/cvweb/Pictures1/colorpixels.png\" alt=\"Color Pixel Values\" style=\"width: 300px; height: 200.145px; margin: 0px;\"/>\n",
    "\n",
    "**(Provided by [A Standford Tutorial on image filtering](https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html) )*which in itself is a really great tutorial, you should read it.**\n",
    "\n",
    "**Here is an example of a single layer:**\n",
    "<img src=\"http://hosting.soonet.ca/eliris/remotesensing/LectureImages/pixel.gif\" alt=\"Grayscale Pixel Values\" />\n",
    "**(Provided by [A Standford Tutorial on image filtering](https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html) )*which in itself is a really great tutorial, you should read it.**\n",
    "\n",
    "**What does it mean to be linear?:**\n",
    "- **In the case of images, we don't want a 2-dimensional representation of an image, we want a 1 dimensional representation of the image. Why? As mentioned before, this is how we conduct machine learning, or a Convolutional Neural Network (CNN) in this case. The 1-dimension is the same thing as saying 'linear.'**\n",
    "\n",
    "**How do we go from 2-dimensions to 1-dimension/linear?:**\n",
    "- **Start at the top of left of our 2 dimension grid, from there we will tally up every pixel value in the row. Then we will continue on to the next row and take all of those pixel values and place them on the end of the first row we tabulated. We will continue to do this for every row in the image. We will also do this for every layer that's in the image (in this case it's 3 for Red, Green and blue). This will leave us with 3 long strings of pixel values that represent the red, green and blue spectrums of the color picture.**\n",
    "\n",
    "**Here is a visual example of what's happening:**\n",
    "\n",
    "<img src=\"https://processing.org/tutorials/pixels/imgs/pixelarray.jpg\" />\n",
    "\n",
    "**(sourced from [proccessing.org](https://processing.org/tutorials/pixels/) )**\n",
    "\n",
    "**Note: The above description of the linear process is overly simplified. In most cases involving our Convolution Neural Networks, we will have many more layers than the three that represent the color spectrum. What are these layers? That brings us to our next portion of describing a conv2d, which is short for a two dimensional convolution.**\n",
    "\n",
    "## Conv2d:\n",
    "\n",
    "**What is a convolutional layer?:**\n",
    "- **For starters, the three layers of primary colors are technically a convolutional layer. To put it in perspective, a convolutional layer is a layer dedicated to depict a specific feature of our image. That means our 3 color convolutional layers are for what they sound like, depicting the color of the image(*NOTE: these are also our main factors in image learning, we refer to these as our 'channels'). Also, we will find that there are other methods to extract other features.**\n",
    "\n",
    "**What are features?:**\n",
    "- **A feature is a distinctive property about an object that tells us one particular thing about it. In our case with images, we already know about color. But let's think about the other segments that make up an image. Even with colors, we have various contrasts and intensity of those colors. For instance, some groups of pixels are more blue than the ones around it. This provides a distinctive feature of our image. We can also use certain types of feature detection for lines, curves, edges, sharpness and so on.**\n",
    "\n",
    "**Now that we have a general sense of what layers and features are, let's look at how we aim for these features to generate these layers. If you look at the interwebs, you will find many, many, different words that will generally confuse the shit out of you because nobody is on the same page..even with themselves sometimes.**\n",
    "**In order to accomplish this, we're going to break this into a few nomenclature parts so you can get the hang of the lingo. Then soon you'll be able to point out the non-coherent language usage on the internet, too.**\n",
    "\n",
    "**Filters, Kernels and convolutions, 'Oh, my!':**\n",
    "\n",
    "- **A filter is the word used to describe the method in which we extract certain features we're looking for.**\n",
    "\n",
    "- **A Kernel is a square object we use to overlay on our 2-dimensional image. The Kernal is also a 2-dimensional group of pixels on a much smaller scale than our images (usually around 3x3 but can be any equal combination thereof).**\n",
    "\n",
    "- **An input is referring to our pixelated image in this case. HOWEVER, I want to make it clear that inputs aren't only just images. They can be words, tabulated data and several other things. These will be gone over in later lessons.**\n",
    "\n",
    "- **A feature map is a term used for the convolution layer created by our filter in our kernel, that is applied to our input layer.**\n",
    "\n",
    "- **A convolution is the matrix multiplication result of using the filter method within our kernel that is overlaid on the image.**\n",
    "\n",
    "**Now that we have a sense of these words, let's get into some examples of these filter/kernel combinations. Looking at the image below, you need to think of the blue box as the image, and the green block as the kernel itself. BUT! the numbers within the kernel are the filters! I hope you see that now.**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1642/1*cTEp-IvCCUYPTT0QpE3Gjg@2x.png\" style=\"width: 300px; height: 200.145px;\" />\n",
    "\n",
    "**I will give some examples of filters in a bit, but let's just try to wrap our heads around how we generate the convolution layer with filters in general. If we look at our image below, we can see the kernel (with the filter inside) moving over our blue image box, and generating numbers on the right. What's happening? Matrix multiplication!!!**\n",
    "\n",
    "<img width=\"400\" height=\"250\" srcset=\"https://miro.medium.com/max/552/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 276w, https://miro.medium.com/max/1104/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 552w, https://miro.medium.com/max/1280/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 640w, https://miro.medium.com/max/1400/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 700w\" src=\"https://miro.medium.com/max/1440/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif\" />\n",
    "\n",
    "**(sourced from [towardsdatascience.com](https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2))**\n",
    "\n",
    "**Not sure what matrix multiplication is? That's fine, let me show you a glimpse of how it's applied to our Convolutional Neural Network. If we start at the top left (which is where all images begin) with our kernel (and the filter within it) we are going to multiply every number in the portion of the blue 'image' box (input layer) that's covered by the kernel. In the case below, we can see this; [1x1, 1x0, 1x1], [0x0, 1x1, 1x0], [0x1, 0x0, 1x1]. What do we do with these? welp, let's multiply each of these individually and add up the answers...Which not surprisingly equals 4!! Which is exactly what we have in our box on the right (our newly produced convolutional layer/Feature Map).**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1629/1*ghaknijNGolaA3DpjvDxfQ@2x.png\" style=\"width: 300px; height: 200.145px;\" />\n",
    "\n",
    "**(sourced from [towardsdatascience.com](https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2))**\n",
    "\n",
    "**The moving image above shows how the kernel (with filter) moves along our blue box image representation (input layer). It's important to note a reminder that our image pixels are NOT simply zeros and ones. That was just to keep the demonstration simple enough. It's also important to note that our filters are also not just zeros and ones. But, they will only range from 0 to 9. Let's take a look at some examples;**\n",
    "\n",
    "- **Here is an image for filtering:**\n",
    "\n",
    "<img src=\"https://mlnotebook.github.io/img/CNN/android.png\" style=\"width: 200px; height: 200.145px;\" />\n",
    "\n",
    "- **Here is a filter used to detect horizontal lines:**\n",
    "<table><tr>\n",
    "<td> <img src=\"https://mlnotebook.github.io/img/CNN/horizFilter.png\" style=\"width: 200px; height: 200.145px;\" /> </td> <td> <img src=\"https://mlnotebook.github.io/img/CNN/horiz.png\" style=\"width: 200px; height: 200.145px;\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "- **Here is a filter used to detect vertical lines:**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"https://mlnotebook.github.io/img/CNN/vertFilter.png\" style=\"width: 200px; height: 200.145px;\" /> </td> <td> <img src=\"https://mlnotebook.github.io/img/CNN/vert.png\" style=\"width: 200px; height: 200.145px;\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "**(Sourced from [this cool notebook](https://mlnotebook.github.io/post/CNN1/))**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I would like to take some time to appreciate what we're doing here with our generated convolution layers/features maps. These are actual portions of our image. We can run all sorts of filters on our inputs, to include diagonals, slopes, edges...etc... and it essentially hacks apart our image into as many layers as we've created. Let's put it into perspective.**\n",
    "\n",
    "**Let's say we have 64 convolution layers we made out of our input image. This is all of the colors, lines, shapes...etc.. What this really means is that we have 64 parts of a single image. If we put them all back together, it would show you the original image you've started with. Here is an example from our pieces of the little droid guy above:**\n",
    "\n",
    "<img src=\"https://mlnotebook.github.io/img/CNN/both.png\" style=\"width: 200px; height: 200.145px;\" />\n",
    "\n",
    "**As you can see, he has been made whole again! Of course, only those two features were added together to make the image. We still have other layers of colors and whatnot. Regardless, this is a very important distinction to understand, these are actual objects that can be manipulated. Here's another example:**\n",
    "\n",
    "**Here we have an original image. Then we ran a filter over it that 'smooths' out the edges. Then we subracted this produced convolutional layer from our original, and then we have an altered image:**\n",
    "\n",
    "<img src=\"https://ai.stanford.edu/~syyeung/cvweb/Pictures1/sharpening1.png\" style=\"width:641px;height:310px\" />\n",
    "\n",
    "**Poof! Now we can see what our filtered convolutional layer looked like.**\n",
    "\n",
    "**Now I would like to address the elephant in the room that you maybe didn't see. Sure, you've seen what filters can look like BUT! When we do our machine learning, some of these filters are actually random! That's right, random. This is the learning that specifically being done when we're training our models.** \n",
    "\n",
    "**That's how these models are so effective. The computer is better at randomly coming across certain features that allow it to effectively make correct classifications. This goes back and ties in with our multiple layers in our Convolutional Neural Network. This is just one part that we have spent all this time learning about. But, it's foundationally the bedrock for which all of our machine learning grows from. So I hope you have a better understanding of the conv2d.**\n",
    "\n",
    "**What about the other columns from the cell output below? Noted as the; output shape, param# and trainable columns. Let's go over that.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type)         Output Shape         Param #    Trainable \n",
      "======================================================================\n",
      "Conv2d               [8, 64, 180, 240]    9408       False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 180, 240]    128        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 64, 180, 240]    0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [8, 64, 90, 120]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 64, 90, 120]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 64, 90, 120]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 64, 90, 120]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 64, 90, 120]     36864      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     73728      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 128, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     8192       False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 128, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 128, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 128, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 128, 45, 60]     147456     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     294912     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     32768      False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 23, 30]     589824     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     1179648    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 12, 15]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     131072     False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 12, 15]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 12, 15]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     2359296    False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 512, 12, 15]     1024       True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 12, 15]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 1024, 12, 15]    4719616    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 1024, 12, 15]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 12, 15]     4719104    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 12, 15]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 1024, 12, 15]    525312     True      \n",
      "______________________________________________________________________\n",
      "PixelShuffle         [8, 256, 24, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "ReplicationPad2d     [8, 256, 25, 31]     0          False     \n",
      "______________________________________________________________________\n",
      "AvgPool2d            [8, 256, 24, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 1024, 12, 15]    0          False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 23, 30]     512        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 23, 30]     2359808    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 23, 30]     2359808    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 23, 30]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 1024, 23, 30]    525312     True      \n",
      "______________________________________________________________________\n",
      "PixelShuffle         [8, 256, 46, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "ReplicationPad2d     [8, 256, 47, 61]     0          False     \n",
      "______________________________________________________________________\n",
      "AvgPool2d            [8, 256, 46, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 1024, 23, 30]    0          False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 128, 45, 60]     256        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 384, 45, 60]     1327488    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 384, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 384, 45, 60]     1327488    True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 384, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 384, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 768, 45, 60]     295680     True      \n",
      "______________________________________________________________________\n",
      "PixelShuffle         [8, 192, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "ReplicationPad2d     [8, 192, 91, 121]    0          False     \n",
      "______________________________________________________________________\n",
      "AvgPool2d            [8, 192, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 768, 45, 60]     0          False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 90, 120]     128        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 90, 120]    590080     True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 256, 90, 120]    590080     True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 256, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 512, 90, 120]    131584     True      \n",
      "______________________________________________________________________\n",
      "PixelShuffle         [8, 128, 180, 240]   0          False     \n",
      "______________________________________________________________________\n",
      "ReplicationPad2d     [8, 128, 181, 241]   0          False     \n",
      "______________________________________________________________________\n",
      "AvgPool2d            [8, 128, 180, 240]   0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 512, 90, 120]    0          False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 64, 180, 240]    128        True      \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 96, 180, 240]    165984     True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 96, 180, 240]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 96, 180, 240]    83040      True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 96, 180, 240]    0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 192, 180, 240]   0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 384, 180, 240]   37248      True      \n",
      "______________________________________________________________________\n",
      "PixelShuffle         [8, 96, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "ReplicationPad2d     [8, 96, 361, 481]    0          False     \n",
      "______________________________________________________________________\n",
      "AvgPool2d            [8, 96, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 384, 180, 240]   0          False     \n",
      "______________________________________________________________________\n",
      "MergeLayer           [8, 99, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 49, 360, 480]    43708      True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 49, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 99, 360, 480]    43758      True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [8, 99, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "MergeLayer           [8, 99, 360, 480]    0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [8, 12, 360, 480]    1200       True      \n",
      "______________________________________________________________________\n",
      "\n",
      "Total params:  41133018\n",
      "Total trainable params:  19865370\n",
      "Total non-trainable params:  21267648\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Shape: \n",
    "\n",
    "**[8, 64, 180, 240] What are these numbers!? Let me explain by starting with the first one '8.' If you look back to our previous cell in the notebook, you might remember that we created an object called 'bs' with the value of '8.' If you remember thus far, that is our batch size. As a reminder, we use that batch size to create chunks of our data totaling 8 groups. This is generally for computational purposes.**\n",
    "\n",
    "**The second number '64' is actually the amount of convolutional layers we've created (filters to be applied). When did we do this? Well, 'we' didn't. These are mostly convolutional layers taken from our base architecture of resnet34, which were in turn generated by 64 filters just like some of the ones we've described previously.**\n",
    "\n",
    "**The last two numbers are actually pretty simple. They are the pixel size of our images. In this case we are starting with our images with dimensions of 180 pixels across (width) and 240 pixels in length (height). We will discuss more about these sizes as they change through the other layers of our network.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param #:\n",
    "\n",
    "**This number accounts for the total number of items that are generated by our inputs and the computations done upon them, in this case it was by our Conv2d. *Keep in mind, this is not the only computation that will increase the number of parameters. In fact, each row is stating how many parameters were created ONLY on this row. There will be more created when we go through our layers.**\n",
    "\n",
    "**What are these 'items' I'm referring to? It is actually the number of weights that were generated. So total parameters are the total amount of weights that were calculated per row. And of course we remember that weights are the bread and butter of machine learning.**\n",
    "\n",
    "**Now I'd like to try and find out where these parameters came from. In order to do that, I need to fill you in on some techniques that will be applied during this stage. Namely, padding and striding.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding:\n",
    "\n",
    "**Padding is used to ensure the center of our kernel block can start off on the very top left pixel, and capture all pixels with it's center throughout the convolution. What makes up padding? Simple! It's a layer (or more) of zeros around our original convolution. So if we had a 180 x 240 before and then added one padding layer, we will now have a 181 x 241 convolutional layer. Here is a visual example of a smaller convolution being padded:**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/632/1*nYf_cUIHFEWU1JXGwnz-Ig.gif\" style=\"width:250px;height:250px\" />\n",
    "\n",
    "**Here, the white space indicated the padding layer, the blue box shows us the original size of our convolutional layer we used and then the green blocks indicate the pooled calculation performed in our shadowed kernel box. Hopefully that makes a little more sense.**\n",
    "\n",
    "### Striding:\n",
    "\n",
    "**Striding is utilized to help out with our recurring computation burdens. As we have hinted above, why double our calculations done by our kernels/filters? It seems that in most cases, we don't need to. And that's how striding is going to help out.**\n",
    "\n",
    "**Look back at our image above. We can see that it is hitting every single pixel with the center of the kernel. Now, let's add stridding to the mix:**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/632/1*1VJDP6qDY9-ExTuQVEOlVg.gif\" style=\"width:250px;height:250px\" />\n",
    "\n",
    "**Above we can see the same padding done around the same size convolution as shown in the padding image above. The difference now is that our kernel is moving over two pixels instead of one. We can clearly see the difference in the size of the results shown by the green box. Instead of a 5x5, we now have a 3x3. For those math wizards out there, that's a difference of 16 pixels. Or in other words, that's a difference of 16 bits of information. If we do that for all of our convolutional layers produced from our original filtering, we have saved A LOT OF COMPUTATIONAL TIME. And that is the benefits of both stridding and padding.**\n",
    "\n",
    "**Now let's get back to our summary chart shown above. To have it make more sense, I took a modified snippet of it from the fast.ai docs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>torch.Size([3, 352, 352])\n",
    "\n",
    "    [...]\n",
    "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    [...]\n",
    "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "    [...]\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (8): Linear(in_features=512, out_features=37, bias=True)\n",
    "\n",
    "\n",
    "======================================================================\n",
    "Layer (type)         Output Shape         Param #    Trainable \n",
    "======================================================================\n",
    "Conv2d               [64, 176, 176]       9,408      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [64, 176, 176]       128        True      \n",
    "______________________________________________________________________\n",
    "[...]\n",
    "MaxPool2d            [64, 88, 88]         0          False    \n",
    "______________________________________________________________________\n",
    "Conv2d               [64, 88, 88]         36,864     False     \n",
    "[...]\n",
    "______________________________________________________________________\n",
    "Linear               [37]                 18,981     True</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brace yourself. I know these coding things can be daunting, but stick with me. Let's start with our first line:**\n",
    "\n",
    "**Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)**\n",
    "\n",
    "**Beginning with the first input of '3', I can assert that this is in regards to our three primary colors. Which are also referred to as 'channels' in the documents. These inputs are separated from our other features specifically for our image learning. Remember, in a general sense, we can apply this same technique to other applications of machine learning beyond vision. But, we separate these specific channels for visual learners to enhance accuracy. I would also like to point out that we can have more than three channels. In another lesson, we can see that depth is another potential channel to use. In any case, the default will be three. Which means our one image is now three items.**\n",
    "\n",
    "**Our next input in the line of code is '64.' We should be familiar with this part, it's the number of filters we want to apply to our 3 image channels. So far that means we will have 64x3 (192) parameters (filters in this case) produced. Now, I can't say for certain if the underlying framework applies known filters with the kernel OR if there is a mix of randomized and known. In either case, the model would likely learn those 'known' as a natural progression so we'll just leave it as it lies.**\n",
    "\n",
    "**Next we have a kernel size of 7x7 as indicated by 'kernel_size=(7, 7).' There's a rational behind this default setting. So get ready, we're going to have to use some brain power and imaginations to see how this plays in with the stride and padding.**\n",
    "\n",
    "**Here we go. The example above shows an original image size of 352x352. This is likely what we ended up with after a typical transform function on our data sets of images. As we can see from the next parts of our line of code, we have a stride of 2x2 (so two steps right and then two steps down at the end) then a padding layer of 3 (three zeros around our original 352x352, meaning +3 on all sides and +6 for each row and column). With this extra padding, our input image size is now 358x358.** \n",
    "\n",
    "**You might be saying to yourself \"358 isn't divisible by 7,\" which is correct. But you're thinking about it wrong. Remember we have a 7x7, which means that our center block has 3 blocks to the left and 3 blocks to the right. AND we are only doing half of the pixels because we're hitting every other one with the kernel. Adding this layer of padding is just balancing out the size of our kernel. This allows our kernel to calculate half of our original pixel values of our image. So, that means our kernel will be able to take 176 steps to the right and 176 steps down. WHICH IS HALF OF OUR ORIGINAL IMAGE SIZE!!** \n",
    "\n",
    "**Now you can see why we have these defaults set to these numbers. In the future, we will see other variations in sizes of our images, but they will have a scaled version of our basic default parameters to ensure that we are making correct mathematical inputs.**\n",
    "\n",
    "**Let's do some counting. We have 3 channels created from our input image, which is our red, green and blue colors. Next we are going to apply our 64 filters/kernels to each of our 3 channels. Then each of these kernels is the size of a 7x7 grid. This means that we are going to have a total of;**\n",
    "\n",
    "$3x64x7x7 = 9408$ **Parameters!**\n",
    "\n",
    "**Cool, but what does that even mean? Think of it this way, we're going to have a 7x7 kernel that will provide 49 pieces of information. That means we are going to have 49 pieces of information for every filter we're going to apply to each of our 3 channels. That's why we multiply them all together to reach our answer. I hope that makes things a little more clear.**\n",
    "\n",
    "**To put it in other words, each 7x7 filter does the below type of multiplication, hitting every other pixel across and down our original image size of '358x358' (NOTE: THIS IS THE TOTAL SIZE WITH PADDING!!). Which allows us to take 176 steps to cross and down. Here's a throwback to our previous kernel visual:**\n",
    "\n",
    "<img width=\"400\" height=\"250\" srcset=\"https://miro.medium.com/max/552/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 276w, https://miro.medium.com/max/1104/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 552w, https://miro.medium.com/max/1280/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 640w, https://miro.medium.com/max/1400/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif 700w\" src=\"https://miro.medium.com/max/1440/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif\" />\n",
    "\n",
    "**Here's where it all comes together. We now have a set of 49 calculations to perform 352 times using each of our 64 types of filters (176 times across the image and 176 times down the image gives us our '352 times' above). Then we are going to do this once for each of our 3 channels taken from the original image.** \n",
    "\n",
    "**How many calculations is that you ask? It is $3,311,616$ calculations....PER INPUT IMAGE!!! not impressed yet? Remember, we have over 700 original images AND we have even made transformed copies of those images. Even if we only counted our 700, that is still $2.32x10^9$ calculations(2.32 Billion). Still not impressed? Don't forget, this is only our first round within our visual learner model. If we look back to our 'learn.summary()' output above and scroll to the bottom, we will find there are a total of 41,133,018 parameters AND 19,865,370 of those are trainable (we will change an recalculate them). Even if we only ran through all parameters once and our trainable ones a second time (assuming we have about 3 million calculations per round) we are already at $1.9x10^{24}$ computations.** \n",
    "\n",
    "**That is a lot of calculations! This is why we utilize linear algebra and graphic card processing to assist us with our efforts.** \n",
    "\n",
    "**It's important to note that computationally, we don't always want our parameters to be a large number. That's why we apply techniques to find a balance between the size of our image inputs (then subsequent parameter size) and the time it takes to computate them. All while not trying hinder our performance of correct answers in our model.**\n",
    "\n",
    "**we can see these types of techniques invoked in our example chart above, we will also go through each of these in detail a little later.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable:\n",
    "\n",
    "**What does the trainable column mean? Here we have a fairly simple answer. This just indicates whether this layer is allowed to have weight modifications performed on it.** \n",
    "\n",
    "**I had previously mentioned that these weights are passed forward to the next layers. Once it reaches the last layer and an answer is determined by the learner model, we calculate the effects of these weights on the outcome of the answer our model has reached. Then we pass these weights back into the calculations to determine which were the most effective. And then, we do it all over again, and again, until we're pleased with our accuracy of our model.**\n",
    "\n",
    "**Given this understanding, we can see why it tells us at which portions of the training we are allowing these weight manipulations to occur. That means this part is essentially there for informational purposes to allow us more control and understanding of what's going on in our model.**\n",
    "\n",
    "**Let's move on to the next row in our summary table above, which is our BatchNorm2d.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm2d:\n",
    "\n",
    "**As said previously, lengthy parameters, and large amounts of them, can make for looonnnggg unwanted computational power and time. BatchNorm is one of several techniques that allows us to reduce some of the computational strain. Without being too mathy on you, like this;**\n",
    "<img src=\"https://miro.medium.com/max/1277/1*kyVa9UTnMIpOYUE0DDcb2A.png\" style=\"width:641px;height:450px\" />\n",
    "\n",
    "**(sourced from [medium.com](https://medium.com/deeplearningmadeeasy/everything-you-wish-to-know-about-batchnorm-6055e07fdce2#:~:text=What%20is%20BatchNorm%3F,can%20use%20higher%20learning%20rates.))**\n",
    "\n",
    "**...I will just try to explain it. We basically don't want our weight numbers to explode into large digits, or implode towards zero. This is bad for processing, and graphics card processors don't like either of these things. So what to do about that? Well, in simple terms, we normalize those numbers that were generated. What is normalize? The dictionary says:**\n",
    "\n",
    "- **Normalize: multiply (a series, function or item of data) by a factor that makes the norm or some associated quantity such as an integral equal to a desired value (usually 1).**\n",
    "\n",
    "**In other words, we want to take our weights we've calculated and change them into more digestible digits. All while keeping them scaled in regards to all other weights and retaining their own unique identity among them. This is exactly what BatchNorm is doing.** \n",
    "\n",
    "**The math behind isn't as complicated as it seems. In simple terms we are doing the following;**\n",
    "\n",
    "- **Taking the mean of our batch that we are currently processing (so let's say 1 of the 8 total).**\n",
    "\n",
    "- **Next we take the variance, which is adding up the difference between how far off each individual weight is from the previously calculated mean of the batch that it's in (this is also squared, which is done for mathematical reasons we won't get into).**\n",
    "\n",
    "- **Now we NORMALIZE it. This is the portion that scales all of our weights between negative one, zero and one (-1<0<1). We basically take each individual weight and subtract the mean of the batch from it. Then we simply divide by our calculated variance minus any bias (which is another mathematical concept we won't get into here).**\n",
    "\n",
    "**There we have it. BatchNorm in a nutshell. But what is this param# of 128? Let's see if I can guess this right.** \n",
    "\n",
    "**I 'THINK' (not 100% sure) that this is a tally of the total number of weights calculated in this step. Remember that we start off with 64 convolutional layers that were calculated in the beginning. Each one of these layers has 1 weight assigned to it (this weight could be random if we're just starting, or we could be borrowing a pre-calculated weight from another backbone architecture we're using).**\n",
    "\n",
    "**Next, when we run these 64 weights through our normalization we are essentially producing another 64 weights. Albeit, these weights have now been normalized for processing purposes. BUT! On a scale level, they are essentially the same distance apart with respect to the other weights. They're just scaled down. There we have it, we store away our original weights and then store away our new calculated normalized weights. A total of 128! Thanks for sticking with me on that one.**\n",
    "\n",
    "**We can also note that this layer is 'trainable.' We can see why, since our weights are subject to change after we pass them forward to the final activation layer and then send those answers back for the next round of processing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu:\n",
    "\n",
    "**This is properly named; 'Rectified Linear Unit.' And I'm going to do you a favor by simply explaining this one. Remember when we calculated those weights using BatchNorm? Well, those answers came out in a range from -1 to 1. Guess what? The negative weights don't really do much for us. And it's been proven effective to remove them from the training computations.**\n",
    "\n",
    "**Removing these unwanted weights is where our ReLu comes into play. This is essentially a function that removes any value less than 0. Why do this? Well, it greatly speeds up our computation time and increases the accuracy. How does it do that? Easy! If we don't have useless numbers clogging up our view, we can get to where we're going much faster. It's as simple as that.**\n",
    "\n",
    "**I would like to note that there are several types of these activations. Some include a small range of values just below zero, some include some values below that and so on. We use the ReLu because it has just been shown in practice to be more effective. I'm sure someone is going to write a fancy paper about it at some point, but we'll just rough it down here in the slums. No need to get fancy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CNN 'Layer':\n",
    "\n",
    "**These three items of Conv2d, BatchNorm2d and ReLu are our basic 'layer' of a Convolution Neural Network model `(not to be confused with the convolution layer outputs from Conv2d, that just simply explains that each convolution is a 'layer of the image, not a layer of our neural network model)`. Below is an example of how these layers fit into the grand scheme;**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1283/1*kToStLowjokojIQ7pY2ynQ.jpeg\" style=\"width:641px;height:310px\" />\n",
    "\n",
    "**(Sourced from [towardsdatascience](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53))**\n",
    "\n",
    "**We essentially rinse, wash and repeat until we feel that our selected amount of layers accomplishes our learning task for the model training. If you look in the table output in our cell above, and the image above, you'll see some additional components to our typical model. We will get into the end parts of the model later, but first we will discuss the MaxPool2d function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool2d (and AvgPool2d):\n",
    "\n",
    "**As I have mentioned previously, computation time and accuracy is pretty crucial to machine learning. You don't have to be a computer scientist to understand that if we generate 40,000 parameters at a length of 50 digits, that's a lot to handle. Even for a computer. Thankfully, a lot of clever people (especially at fast.ai) have utilized fantastic methods to reduce this computational burden, all while leaving accuracy intact OR increasing it.**\n",
    "\n",
    "**Two of those methods of reducing burden are using MaxPool and AvgPool. Let's think about where we are at in the layers of our model. We have already generated our convolution layers from applying kernels/filters to our input data. Then we ran through a round of normalization and activation (using BatchNorm2d and ReLu respectively). Now we can implement Pooling. But what is pooling?**\n",
    "\n",
    "- **Pooling is both a reduction in size of the computed features from our convolutions (64 of them starting off in our model), and it allows us to 'remove' some of the non-useful features in those same convolutions.**\n",
    "\n",
    "**Keeping our Pooling definition in mind, we are reducing the pixel sizes of our convolutions and concentrating our values on the more important features of our images. How are we doing this? Well, something like this picture below;**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/634/1*uoWYsCV5vBU8SHFPAPao-w.gif\" style=\"width:500px;height:310px\" />\n",
    "\n",
    "**(source from our friend at [towardsdatascience.com](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53))**\n",
    "\n",
    "**What are we looking at in the above image? Thinking back to our previous picture examples, our orange box image on the right is one of our 64 convolutional layers calculated from our image. But what's that shadowy thing floating over it? Would you say it kind of looks like a kernel? That's because it is!!!**\n",
    "\n",
    "- ***Sidebar: Now we can see a prime example of how a kernel is not the same thing as a filter. A filter is the thing placed into the kernel. As we will see shortly, our Max Pool and Average Pool are the things placed into this particular kernel. These pooling items are going to be the function that the kernel is performing, just like the matrix multiplication function performed by our filter in the convolutions of our input images.***\n",
    "\n",
    "**What about the green box on the left? This is going to be the result of the calculation performed by one of the pools within our kernel. What is this calculation? If you could wager a guess, it's either going to be the averaging of all the numbers within the kernel or the maximum number within the kernel. What does this look like? Check it out below;**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/954/1*KQIEqhxzICU7thjaQBfPBQ.png\" style=\"width:500px;height:310px\" />\n",
    "\n",
    "**(source from our friend at [towardsdatascience.com](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53))**\n",
    "\n",
    "**Let's look at the image above and pretend like our kernel is a 2x2 size. Then let's pretend like it's floating from each pixel starting in the top left and working its way towards the right and down. Now we can see how each color is calculated as it moves across our convolutional layer. The Max layer at the top right is just taking the highest number, and the Average layer is adding up all 4 numbers in the kernel box then dividing by 4.**\n",
    "\n",
    "**As we have seen before, our kernels can be various sizes, but will always be a square (or cubed). It's also important to note that we have several options on how we want the kernel to move across the pixels, and also several options on what we do with those calculations. AND! In other cases, we can also combine the results of these calculations `(by summing them together, this would typically be done for a kernel using filters for the convolutional layer)` and thereby reduce the total amount of layers OR! We can increase the amount of layers if we want to do both Max and Average pooling.** \n",
    "\n",
    "**Let's get into some examples. First, let's look at a kernel moving along 3 convolution layers of our input image. To be simple, we're going to have these represent our red, green and blue color spectrums.**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/522/1*NsiYxt8tPDQyjyH3C08PVA@2x.png\" style=\"width:250px;height:250px\" />\n",
    "\n",
    "**In the above example, you can see that this kernel is a cube. It starts in the top left, hitting each pixel moving to the right and then moving down once it hits the end of the row. We have already gone over some advanced movements, such as padding and striding, but we didn't think about how we could do more than one layer (or channel) at a time. Think about this, we can move across 3 layers like we are above BUT only calculate one layer as the output. In other words, we went from 3 dimensions to 2 dimensions. It would look something like this;**\n",
    "\n",
    "<img src=\"http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png\" />\n",
    "\n",
    "**(we can thank a Mr. [Dave Voyles](https://notebooks.azure.com/DaveVoyles/projects/TensorFlow-Examples/html/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb) for this)**\n",
    "\n",
    "**I mentioned this to reiterate the point that there are countless ways that may have a benefit towards helping our models to learn better. We don't always know, or assume what these combinations would be, or why for that matter. But we do know that using these various methods does in fact lead to solutions that are just simply beyond our regular brains to calculate. That's why it's machine learning and not brainy learning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>torch.Size([3, 352, 352])\n",
    "\n",
    "    [...]\n",
    "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    [...]\n",
    "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "    [...]\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (8): Linear(in_features=512, out_features=37, bias=True)\n",
    "\n",
    "\n",
    "======================================================================\n",
    "Layer (type)         Output Shape         Param #    Trainable \n",
    "======================================================================\n",
    "Conv2d               [64, 176, 176]       9,408      False     \n",
    "______________________________________________________________________\n",
    "BatchNorm2d          [64, 176, 176]       128        True      \n",
    "______________________________________________________________________\n",
    "[...]\n",
    "MaxPool2d            [64, 88, 88]         0          False    \n",
    "______________________________________________________________________\n",
    "Conv2d               [64, 88, 88]         36,864     False     \n",
    "[...]\n",
    "______________________________________________________________________\n",
    "Linear               [37]                 18,981     True</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we look back to our table above, we left off at our MaxPool2d layer. If we take a look at the output shape after that function, we can see that we reduced the size of our convolutions by half.**\n",
    "\n",
    "**Using everything that we've just learned, why half? Well, let's go back to our fast.ai doc's snippet of code;**\n",
    "\n",
    "**MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)**\n",
    "\n",
    "**We know these things now. But, let's go over it. First, we can see that our padding size is 1. It was subtle, but you may have noticed a pattern with that. Our padding size is always (kernel_size-1)$\\div$2. This is because our kernel size is always an odd number to form a proper square that can capture all of our original pixels.**\n",
    "\n",
    "**Next we have a stride of 2. Which is going to be what cuts down on the total amount of pixels we hit. In this case, a stride of two will cut down our amount of pixels by half! That means we now have half of the image size.**\n",
    "\n",
    "**Excellent, it all comes together. Now let's move along to the next set of Conv2d.**\n",
    "\n",
    "## Repeating the process:\n",
    "\n",
    "**It's easy to overlook, and hard to find a good digestible answer too, but what exactly are our other Conv2d's running a filter on? If the first Conv2d was run on the original image, then what is this 2nd, 3rd or 4th...ect..convolution filter running on? Is it each subsequent previously made convolutional layers??!!! Sure is. Essentially, the output from a convolution ends up being the input for the next convolution calculation. Of course, we'll likely run our pooling and activation layers first.**\n",
    "\n",
    "**It's good to keep in mind that the layers we're running in our fastai aren't just passed on and forgotten. Our typical operation involves the ResNet34, which stands for a 34 layer residual network. What does that mean? I won't actually bore you with the details. It is essentially a finely tuned methodology used to train our models. Here is a picture of it compared to other similar methods:**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/986/0*Si4ckM1MrkUxTaDH\" />\n",
    "\n",
    "**(Sourced from [Towardsdatascience.com](https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4))**\n",
    "\n",
    "**The key difference is that we have what is called a 'skip' connection. And those are the arrows you see skipping over some layers in the image above. Why do this? Because it works. Just like I've said before, there are probably fancy papers (or will be at some point) that go into detail of why this worked. But, it essentially was just tried out. And then it worked better than all the other ones. And that's how resnet34 was born.**\n",
    "\n",
    "**We can clearly see there is some connective benefit of being able to see previous information and calculating it into computations further down the line. Due to the vastness in the amount of computations performed on these levels, it's more difficult to pinpoint exact spots of enhancement on purpose. That being said, many of the advancements are brought about by trial and error, accidents, and some lucky foresight.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Layers:\n",
    "\n",
    "**I hope, at least, one of you stuck around to get to this part. And if you did, I hope this part will make more sense to you. Let's take a look at the model as it is laid out in Python;**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sequential(\n",
    "  (0): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace)\n",
    "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "    (4): Sequential(\n",
    "      (0): BasicBlock(\n",
    "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (1): BasicBlock(\n",
    "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (2): BasicBlock(\n",
    "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (5): Sequential(\n",
    "      (0): BasicBlock(\n",
    "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (downsample): Sequential(\n",
    "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (1): BasicBlock(\n",
    "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (2): BasicBlock(\n",
    "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (3): BasicBlock(\n",
    "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (6): Sequential(\n",
    "      (0): BasicBlock(\n",
    "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (downsample): Sequential(\n",
    "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (1): BasicBlock(\n",
    "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (2): BasicBlock(\n",
    "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (3): BasicBlock(\n",
    "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (4): BasicBlock(\n",
    "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (5): BasicBlock(\n",
    "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (7): Sequential(\n",
    "      (0): BasicBlock(\n",
    "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (downsample): Sequential(\n",
    "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (1): BasicBlock(\n",
    "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "      (2): BasicBlock(\n",
    "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace)\n",
    "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (1): Sequential(\n",
    "    (0): AdaptiveConcatPool2d(\n",
    "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
    "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
    "    )\n",
    "    (1): Flatten()\n",
    "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): Dropout(p=0.25)\n",
    "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
    "    (5): ReLU(inplace)\n",
    "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (7): Dropout(p=0.5)\n",
    "    (8): Linear(in_features=512, out_features=37, bias=True)\n",
    "    (9): BatchNorm1d(37, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
    "  )\n",
    ")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, I'm sure the first thing you did was count up the number of 'conv2' items that were in here. Then I'm sure it was a total of 34, just as you expected it to be. Because you just knew that was a ResNet34.**\n",
    "\n",
    "**I wanted you to see this so you can explicitly understand the steps involved with the model. First we see the beginning part that we're all familiar with by now, then we see it break off into 'BasicBlocks' of two. What is this for? Well, it's essentially a class that calls the non-changeable parts of our model. i.e. we're not changing the outputs, or utilizing some fancy computations like so;**\n",
    "\n",
    "`(downsample): Sequential(\n",
    "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)`\n",
    "         \n",
    "**What is this above? This is the 'skip' connection that we discussed previously. As you can tell, we are quite literally putting the old output two layers down the line into our new output. You might also notice that our second input changed from 64 to 128.**\n",
    "\n",
    "**Okay, what's this now? A while back I mentioned that the first 2 inputs in our Conv2d code are the channels in and channels out respectively. Of course, originally it started with the 3 red, green, blue channels from the start. Then from there our first output was 64 filters, which is also known as...channels! Now, this is an important concept to understand, with Conv2d we are choosing how many outputs our Conv2d will be producing. In the case above, we had already increased the original thread of channels out so we needed to play catch up with our old output (therefore we increased it to 128).**\n",
    "\n",
    "**If you scroll towards the end, you will see something somewhat familiar with our adaptiveAvgPool2d/adaptiveMaxPool2d. We already know what average and max pooling is, but what is this adaptive stuff?**\n",
    "\n",
    "**To put it in easy terms it is going to create a specific output of 2 dimensions instead of the 3 dimensions it currently has. We have already had a glimpse of how this is done. Instead of pooling over a 2x2 grid, we're going to use our cubes. Kind of like so;**\n",
    "\n",
    "<img src=\"https://miro.medium.com/proxy/1*qyc21qM0oxWEuRaj-XJKcw.png\" />\n",
    "\n",
    "**(sourced from [medium.com](https://medium.com/@joeyism/creating-alexnet-on-tensorflow-from-scratch-part-2-creating-alexnet-e0cd948d7b04))**\n",
    "\n",
    "**A good question would be; how does it calculate each layer (512 in this case) into 1 layer? Well, I can't find a clear answer (I almost thought that all 512 layers were calculated at the same time, this can't be correct because we still have an output of 1024 for our BatchNorm below). If we look at BatchNorm below, we must assume that there is a 512 channel produced for each of our average and max pooling (since one's output must match the next input). Why would I say that? Because of this piece here:**\n",
    "\n",
    "`    (0): AdaptiveConcatPool2d(`\n",
    "\n",
    "**The above is simply a technique that puts together (concatenates) the max pooling and average pooling (piecing together two 512 channel poolings). It's another effective method that increases the effectiveness of our learner model. Now finally, we can see the last part:**\n",
    "\n",
    "` (1): Flatten()\n",
    "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): Dropout(p=0.25)\n",
    "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
    "    (5): ReLU(inplace)\n",
    "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (7): Dropout(p=0.5)\n",
    "    (8): Linear(in_features=512, out_features=37, bias=True)\n",
    "    (9): BatchNorm1d(37, eps=1e-05, momentum, affine=True, track_running_stats=True)`\n",
    "    \n",
    "**Let's go over these one by one:**\n",
    "\n",
    "- **1: Flatten(); This is taking our 2 dimensional output from our concat pooling in the previous step and turning it into 1 long dimension.**\n",
    "\n",
    "- **2 BatchNorm1d(); This is performing a typical batch norm except tweaked for a one dimensional calculation. We can see the input is 1024. Why? because we concatenate two outputs in our avgpool and maxpool previously. And that gives us two 512 pooling groups put together.**\n",
    "\n",
    "- **3 Dropout(p=0.25); We have also previously discussed the dropout method. This is where it takes place in this type of model. With p=0.25 we are giving all of our individual digits in our 1 dimension an equal 25% probability of being dropped from the calculation. It's important to note, that these just don't disappear, they become zero and are still calculated.**\n",
    "\n",
    "- **4 Linear; Here we are reducing the number of output features to 512 (this is a matrix calculation process that is adding our layers together). We need this reduction in order to reach our final output that matches the number of elements that we are trying to predict. We don't do this all at once because we don't want to lose important information.**\n",
    "\n",
    "- **5 ReLu; running an activation function on our weights tied to our channels.**\n",
    "\n",
    "- **6 BatchNorm1d; repeating the normalization.**\n",
    "\n",
    "- **7 Dropout; adding another layer of random dropout with probability of turning zero at 50%.**\n",
    "\n",
    "- **8 Linear; We are again reducing the number of features to match the number of elements we're trying to predict (37 in this case).**\n",
    "\n",
    "- **9 BatchNorm; FINALLY! We are normalizing our weights to produce our round of answers in respect to the one of the 37 possibile answers. This is where we compare and contrast the answers our model produced in regards to the actual answers.**\n",
    "\n",
    "**There we are at the end. We have our gradient answers to calculate these important features and see how they fit in our version of gradient descent (it's been so long that we said that, I didn't want you to forget why we were doing all of this in the first place). Except, it's not really the end. If we assume this is our first epoch of training, this is the part where we take our generated output AND actual answers and run them backwards to be reused in our model. Then at that point, we will run the process again.**\n",
    "\n",
    "**In fact, in real practice, there are other instances where weights and information is getting passed back. I'm going to spare you this because you've already suffered with me enough. We can pick this up in future lessons.**\n",
    "\n",
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
